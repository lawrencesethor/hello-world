---
title: "Homework 1"
author: "Segbehoe, Lawrence Sethor"
date: "January 11, 2019"
output: pdf_document
---


Collaboration: none

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F)
```


```{r packinstall, eval=F}
install.packages("ISLR")
install.packages("knitr")
install.packages("ggplot2")
install.packages("gridExtra")
install.packages("GGally")
```

```{r libload}
library(ISLR)
library(knitr)
library(ggplot2)
library(gridExtra)
library(GGally)
```


# 1. Question 2.4.2 pg 52

Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide *n* and *p*.

  (a) We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.

  (b) We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.
  
  (c) We are interest in predicting the \% change in the USD/Euro exchange rate in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the \% change in the USD/Euro, the \% change in the US market, the \% change in the British market, and the \% change in the German market.
  
## Solution to Question 1

 (a) The scenario described is **regression** because the response variable, CEO salary, is continuous or a quantitative variable. **Inference** because the interest is in understanding which factors (variables) affect CEO salary as opposed to determining CEO salary given a set of factors. $n = 500$ and $p = 3$.
 
 (b) The scenario described is **classification** because the response variable, *success or failure* of a new product, binary/qualitative. **Prediction** since the interest is to know whether the new product will be a *success or failure*. $n = 20$ and $p = 13$.
 
 (c) The scenario described is **regression** since the response variable, \% change in the USD/Euro exchange rate, is quantitative/continuous. **Prediction** because the interest is predicting the \% change in the USD/Euro exchange rate. $n = 52$ and $p = 3$.
 
 
 
 
\newpage

# 2. Question 2.4.4 pg 53

You will now think of some real-life applications for statistical learning.

  (a) Describe three real-life applications in which *classification* might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.
  
  (b) Describe three real-life applications in which *regression* might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.
  
  (c) Describe three real-life applications in which *cluster analysis* might be useful.

## Solution to Question 2

  (a) **Classification**
  
  i. Iris flower is an ornamental plant with sword-shaped leaves and showy flowers typically purple, yellow or white. 50 samples each of iris flower species we collected. The species are iris setosa, verisicolor and virginica. For each of these samples the following measurements were taken: sepal length, sepal width, petal length and petal width. The interest is to predict which species a sample belong using the measurements taken. $n =150$ and $p = 4$. The response is the species and the predictors are sepal length, sepal width, petal length and petal width. The goal is prediction since the interest is to determine which species (class) each sample belong using the measurements taken.
  
  ii. Vole is a small, typically burrowing, mouse-like rodent with a rounded muzzle, found in both Eurasia and North America. Two species of this vole are *Microtus multiplex* and *Microtus subterraneus*. Skulls of 288 specimen from voles found at various places in central Europe collected. For 89 of the skulls, the chromosomes were analyzed to identify their species; $N_1 = 43$ specimens were from *Microtus multiplex* and $N_2 = 46$ from *Microtus subterraneus*. Eight different kinds of measurements were taken from each skull to give 8 variables. Species was not determined for the remaining 199 specimens. The interest here is predict the species of each of the 89 skulls analyzed based on the 8 variables. The response is the species and the predictors are the eight variables. The goal of is prediction since the interest is to determine the kind of species of each sample.
  
  iii. In Bioinformatics, 4189 RNA gene levels from 180 samples of cancer tumor were read. Each of the 80 samples comes from either a male or female. The interest is to predict whether a sample comes from a male or a female based on the 4189 RNA gene levels. The response gender (male or female) and predictors are 4189 RNA gene levels. The goal is prediction since the interest is to predict gender of a sample based on the genes.
  
  **Reference**
  
  Airoldi, J.-P., Flury, B., and Salvioni, M. 1996. Discrimination between two species of Microtus using both classified and unclassified observations. *Journal of Theoritical Biology* **177**, $247-262$.
  
  
  
  (b) **Regression**
  
  i. A director of admissions of a small college selected 120 students at random from the new freshmen class in a study to determine whether a student's grade point average (GPA) at the end of the freshman year can be predicted from the ACT test score and mid-semester exams. Response variable is the GPA at the end of the freshman year and predictor is the ACT test score. The goal of this model is prediction since the interest is to determine GPA based on predictors.
  
  ii. A Tricade Office Equipment Corporation sells an imported three different types of copier on a franchise basis and performs preventive maintenance and repair service on this copier. 45 recent calls from users to perform routine preventive maintenance service were recorded; for each call we have, the number of copiers, copier type and the number of hours spent by the service person in servicing the copiers. The predictor variables are the number of copiers and the type of copier serviced and the response is the total number of minutes spent by the service person. The goal of the company is inference since the interest is find out which of the two predictors is associated with the response.
  
  iii. A substance used in biological and medical research is shipped by airfreight to users in cartons of 1000 ampules. A data is collected, involving 100 shipments. The variables collected involves the number of times the carton was transferred from one aircraft to another over the shipment route and the type of courier (DHL, UPS, or FEDEX). Also, the number of ampules found to be broken upon arrival was recorded. The response variable is the number of ampules found broken upon arrival and the predictors are the type of courier and the number of times the carton was transferred from one aircaft to another over the shipment route. The goal of this scenario is inference since the interest is the find out which of the predictors associated with response variables.
  
  **Reference**
  
  Kutner, M.H., Neter, J., Nachtsheim, C.J. and Li, W. (2004) Applied linear statistical models, 5th Edition. McGraw- Hill Irwin, Boston.
  
  (c) **Cluster Analysis**
  
  i. With 288 specimen of voles skulls collected from various places in central Europe and eight differenct kind of measurements taken from each specimen, *cluster analysis* may useful here to find out the possible number of types (species) of voles within the 288 specimen.
      
  ii. Given 4189 RNA gene levels from 180 samples of cancer tumor cells, *cluster analysis* may be useful in determining the possible number of types(clusters) of cancer tumor within the 180 samples.
  
  iii. *Cluster analysis* is useful to identify how many possible groupings of spending habits of customers given some demographic information such as zip code, family income, shopping habits (how much spent in the last month, how many items bought in the past two weeks, what kind of items bought, etc.)

\newpage

# 3. Question 2.4.6 pg 53

Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a nonparametric approach)? What are its disadvantages?


## Solution to Question 3

Parametric statistical learning makes strict assumption about the functional form, or shape of *f* and reduces the problem of estimating *f* down to one of estimating **a finite set of parameters** while non-parametric statistical learning do not make explicit assumptions about the functional form of *f* and gives room for **infinitly many parameters**. 

Parametric approach is *less flexible* and *more restrictive* which is more appropriate in **inference** is the main interest of the model because it is much more interpretable while non-parametric models are *more flexible* can lead to a complicated estimate of *f* that it is difficult to understand how any individual predictor is associated with the response.

Parametric approaches are simplier and faster to learn from the given training data set while the non-parametric models are more flexible, complicated, slower to learn from the given training data set which may sometimes lead to overfitting.


Disadvantages of parametric approach are:

  * prediction inaccuracy/poor fit 
    
    The model we choose (functional form) will usually not match the true unknown form of *f*. If the chosen model is too far from the true *f*, then our estimate will be poor.
    
  * estimated *f* is contrained by the assumption of a finite set of paramters. 
  
    By choosing a functional form which determines a finite set of parameters, the model is highly stricted by the specified functional form and only small amount of changes occur to the model fit even if more and more data is collected for training and testing.
  
  **Reference**
  
  https://machinelearningmastery.com/parametric-and-nonparametric-machine-learning-algorithms/
  
  http://mlss.tuebingen.mpg.de/2015/slides/ghahramani/gp-neural-nets15.pdf
  
  
    
    
\newpage

# 4. Question 2.4.8 pg 54-55

## Solution (a) - (b)

```{r}
## read the college data into the workspace
college           <- read.csv("College.csv")
rownames(college) <- college[,1]
# fix(college)
college           <- college[,-1]
# fix(college)
```

(a) The data has been read into the working directory using `read.csv()` function.

(b) The `fix()` and the `row.names()` functions have been used to set the row names of the `college` data set.



## Solution (c)

### Solution (c) i
```{r}
kable(summary(college[,1:7]))
```

The number of public schools is less than half of the private schools representing `r round((212/565)*100)`\% of the private schools.

```{r}
kable(summary(college[,c(8:13)]))

kable(summary(college[,14:18]))

```

From the summary it could be observed that the following variables are **fairly symmetrical** based on how close their mean and median values are.
  
  * Outstate
  * Room.Board
  * S.F.Ratio
  * Grad.Rate
  * Top25perc

\newpage
### Solution (c) ii

From the documentation of `pairs()` function, the following function has been used to modify the diagonal and upper panel of the scatter plot matrix.\
`panel.cor()` function for `upper.panel` argument of `pairs()` function to get absolute correlations on the upper panels, with size proportional to the correlations.\
`panel.hist()` function for `diag.panel` argument of `pairs()` function to get histograms on the diagonal.\
`panel.smooth()` function for `lower.panel` argument of `pairs()` function to add LOWESS smoothed line to the scatter plots.\
```{r}

## copied from the r cookbook
panel.cor <- function(x, y, digits=2, prefix="", cex.cor, ...) {
 usr <- par("usr")
 on.exit(par(usr))
 par(usr = c(0, 1, 0, 1))
 r <- abs(cor(x, y, use="complete.obs"))
 txt <- format(c(r, 0.123456789), digits=digits)[1]
 txt <- paste(prefix, txt, sep="")
 if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
 text(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)
}

panel.hist <- function(x, ...) {
 usr <- par("usr")
 on.exit(par(usr))
 par(usr = c(usr[1:2], 0, 1.5) )
 h <- hist(x, plot = FALSE)
 breaks <- h$breaks
 nB <- length(breaks)
 y <- h$counts
 y <- y/max(y)
 rect(breaks[-nB], 0, breaks[-1], y, col="white", ...)
}

pairs(college[,1:10], upper.panel = panel.cor,
      diag.panel = panel.hist,
      lower.panel = panel.smooth,
      main = "Scatterplot Matrix of first ten variables of College data set")
```

There is high positive linear association or correlation between:\
(a) Number of applications received and number of applications accepted.\
(b) Number of applications accepted and number of new students enrolled.\
(c) Number of new students enrolled and number of full-time undergraduates.\

The following variables are fairly symmetrical.\
(a) New students from top 25\% of high school class\
(b) Out-of-state tuition\
(c) Room and board costs\

The following variables are highly skewed to the right.\
(a) Number of applications received\
(b) Number of applications accepted\
(c) Number of new students enrolled\
(d) New students from top 10\% of high school class\
(e) New students from top 25\% of high school class\


```{r ggpairs, fig.width=10, fig.height=10}
ggpairs(college[,1:10], title = "Scatterplot Matrix of first ten variables of College data set")
```



### Solution (c)  iii

```{r, fig.width=6, fig.height=4}
plot(Outstate ~ Private, data = college, col = c("pink","skyblue"),
     main = "Boxplot of Out-of-state tuition by Private colleges",
     cex.main = .9)

```

```{r, fig.width=6, fig.height=4}
ggplot(college, aes(Private, Outstate))  + geom_boxplot(fill = c("pink","skyblue")) + 
  labs(title = "Boxplot of Out-of-state tuition by Private colleges")
```


Out-of-state tuition for non-private colleges is lesser than private colleges. There is higher variance of out-of-state tuition for private colleges.


### Solution iv

#### Summary of distribution of Elite colleges
```{r}
Elite = rep("No", nrow(college))
Elite[college$Top10perc > 50] = "Yes"
Elite = as.factor(Elite)
college = data.frame(college, Elite)

## To see how many elite univeristies are there
summary(college$Elite)


```

```{r , fig.width=6, fig.height=4}
plot(Outstate ~ Elite, data = college, col = c("lightgreen","burlywood2"),
     main = "Boxplot of Out-of-state tuition by Elite colleges", las = 1)

```


```{r, fig.width=6, fig.height=3}
ggplot(college, aes(Elite, Outstate))  + geom_boxplot(fill = c("lightgreen","burlywood2")) + 
  labs(title = "Boxplot of Out-of-state tuition by Elite colleges")
```

Out-of-state tuition for non-elite colleges is lesser than elite colleges. Out-of-state tuition for the elite colleges is a fairly skewed to the left.



### Solution v

#### Base R plots with smaller bandwidth
```{r, fig.width=7, fig.height=6}

plotHist <- function(vec_variables, bin, colours){
par(mfrow = c(2,2))
for (i in vec_variables) {
  hist(college[,i], main = paste("Histogram of ", names(college)[i]),
       nclass = bin, las = 1, col = colours, 
       xlab = paste(names(college)[i]))
}
par(mfrow = c(2,2))
}
plotHist(2:5, 60, "grey")
```

The Apps, Accept and Enroll variables are all higly skewed to the right as seen earlier. The top10perc variable is fairly symmetric but there are significant outlying values



#### ggplot2 alternative varying bandwidth
```{r, fig.width=7, fig.height=6}
BIN <- 300
COL <- "grey"
g1 <- ggplot(college, aes(Apps)) + geom_histogram(binwidth = BIN*2, fill = COL)
g2 <- ggplot(college, aes(Accept)) + geom_histogram(binwidth = BIN*5, fill = COL)
g3 <- ggplot(college, aes(Enroll)) + geom_histogram(binwidth = BIN, fill = COL)
g4 <- ggplot(college, aes(Top10perc)) + geom_histogram(binwidth = 2, fill = COL)

grid.arrange(g1,g2,g3,g4, nrow = 2,ncol = 2)

```



#### Base R plots with bigger bandwidth
```{r}
plotHist(6:9, 11, "skyblue")
```


#### ggplot2 alternative with smaller bandwidth
```{r}
BIN <- 300
COL <- "skyblue"
g1 <- ggplot(college, aes(Top25perc))   + geom_histogram(binwidth = 2,     fill = COL)
g2 <- ggplot(college, aes(F.Undergrad)) + geom_histogram(binwidth = BIN*2, fill = COL)
g3 <- ggplot(college, aes(P.Undergrad)) + geom_histogram(binwidth = BIN,   fill = COL)
g4 <- ggplot(college, aes(Outstate))    + geom_histogram(binwidth = BIN*2, fill = COL)

grid.arrange(g1,g2,g3,g4, nrow = 2,ncol = 2)

```



\newpage
### Solution vi

The following is further exploration of the data set using the boxplot to see if there is a distinction whether or not a colleges is Private for Room.Board, Grad.Rate, Outstate and S.F.Ratio.

#### Base R

```{r basebox, fig.height=9, fig.width=9}
par(mfrow = c(2,2))
plot(Room.Board ~ Private, data = college, col = c("pink","skyblue"), las = 1)
plot(Grad.Rate ~ Private,  data = college, col = c("pink","skyblue"), las = 1)
plot(Apps ~ Private,       data = college, col = c("pink","skyblue"), las = 1)
plot(S.F.Ratio ~ Private,  data = college, col = c("pink","skyblue"), las = 1)
par(mfrow = c(1,1))
```

\newpage
#### ggplot2 alternative

```{r ggbox, fig.height=8, fig.width=9}
g1 <- ggplot(college, aes(Private, Room.Board)) + geom_boxplot(fill = c("pink","skyblue"))
g2 <- ggplot(college, aes(Private, Grad.Rate))  + geom_boxplot(fill = c("pink","skyblue"))
g3 <- ggplot(college, aes(Private, Apps))       + geom_boxplot(fill = c("pink","skyblue"))
g4 <- ggplot(college, aes(Private, S.F.Ratio))  + geom_boxplot(fill = c("pink","skyblue"))

grid.arrange(g1,g2,g3,g4, nrow = 2, ncol = 2)



```

```{r}
ggplot(college, aes(S.F.Ratio, fill = Private)) + 
  geom_histogram(position = "identity", alpha = 0.5)
```


#### Table of Private and Elite variables
```{r}
table(Private = college$Private, Elite = college$Elite)
```

Out of 565 private colleges, only 65 are elite.\
Out of 212 non-private colleges, only 13 are elite.



#### Test of Independence between the Private and Elite variables

The hypothesis for the chi-squared test is:
$$H_0 = \text{Independent}$$ 

$$H_a = \text{Not Independent}$$
```{r}
chisq.test(table(Private = college$Private, Elite = college$Elite))
```

The p-value = 0.03701 from the chi-squared shows that the null hypothesis is rejected at 5\% level of significance. Hence, there is enough evidence to believe that there is association between the distribution of whether a college is Private or not and the distribution of whether or not a college is elite. 


### Brief Summary

(a) The distribution of whether a college is Private or not and the distribution of whether or not a college is elite not independent based on a chisquare test of independence.

(b) Room and board costs is on the average higher in private colleges than non-private colleges.

(c) Graduation rate is on the average higher in private colleges than non-private colleges.

(d) Number of applications received is on the average lower in private colleges than non-private colleges.

(e) Student/faculty ratio is on the average lower in private colleges than non-private colleges. However, there is an outlier in the distribution of student/faculty ratio of the private colleges.

(f) Out of 565 private colleges, only 65 are elite.

(g) Out of 212 non-private colleges, only 13 are elite.




























































